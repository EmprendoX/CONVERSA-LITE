# Conversa Lite

Plantilla m√≠nima para un agente comercial √∫nico con memoria en sesi√≥n, soporte RAG sobre un cat√°logo JSON y un chat web listo para pruebas.

## Caracter√≠sticas principales

- ü§ñ Agente √∫nico configurable mediante `src/agents/primary.json`.
- üß† Memoria en sesiones usando almacenamiento en memoria (ideal para demos y desarrollo).
- üìö Recuperaci√≥n de contexto (RAG) con embeddings de OpenAI sobre `src/data/catalogo.json`.
- üí¨ Interfaz web en React con streaming de tokens (SSE) y feedback por mensaje.
- ‚öôÔ∏è API REST `POST /api/chat` y `POST /api/chat/stream` (SSE).

## Requisitos

- Node.js 18+
- Una clave v√°lida de OpenAI (modelos `gpt-4o-mini` y `text-embedding-3-small`).

## Configuraci√≥n

1. Instala dependencias del backend:
   ```bash
   npm install
   ```
2. Instala dependencias del frontend (solo la primera vez):
   ```bash
   npm run install:web
   ```
3. Crea tu archivo de entorno y agrega la clave de OpenAI:
   ```bash
   cp .env.example .env
   ```
   Edita `.env` y define:
   - `OPENAI_API_KEY`
   - `PORT` (opcional)
   - `RATE_LIMIT_PER_MIN` (opcional, por defecto 60)
   - `MODERATION_ENABLED` (`true|false`)

## Ejecutar el proyecto

1. Inicia la API:
   ```bash
   npm start
   ```
2. En otra terminal, levanta el chat web:
   ```bash
   cd web
   npm run dev
   ```
3. Abre `http://localhost:5173` y empieza a conversar. El frontend guarda tus sesiones en `localStorage`.

## Uso del cat√°logo (RAG)

- Edita `src/data/catalogo.json` con tus productos.
- Ejecuta el generador de embeddings para crear/actualizar el √≠ndice local:
  ```bash
  npm run seed:catalog
  ```
  Este comando crea `src/data/catalogIndex.json` para acelerar las b√∫squedas futuras.
- Desde la interfaz web puedes activar o desactivar el uso del cat√°logo seg√∫n la conversaci√≥n.

## API de chat

`POST /api/chat`

```json
{
  "sessionId": "session-123",
  "message": "Hola, busco una laptop",
  "useCatalog": true
}
```

`POST /api/chat/stream` (SSE)

- Content-Type: `application/json`
- Respuesta: `text/event-stream` con eventos `data: { delta?: string, done?: boolean }`

Ejemplo de consumo en el navegador (simplificado):

```ts
const res = await fetch('/api/chat/stream', { method: 'POST', body: JSON.stringify({ message: 'hola', useCatalog: true }) });
const reader = res.body!.getReader();
const decoder = new TextDecoder();
let acc = '';
while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  const chunk = decoder.decode(value);
  // parsear l√≠neas `data: {"delta":"..."}`
}
```

`POST /api/chat/feedback`

```json
{ "sessionId": "...", "messageId": "...", "rating": "up" }
```

Respuesta:

```json
{
  "reply": "¬°Hola! ¬øQu√© tipo de laptop necesitas y para qu√© la usar√°s?",
  "sessionId": "session-123",
  "agent": {
    "name": "Agente Comercial Inteligente",
    "description": "Asistente √∫nico que comprende el cat√°logo, detecta intenci√≥n de compra y gu√≠a a la persona usuaria hasta la conversi√≥n."
  },
  "memoryProvider": "in-memory",
  "ragResults": [
    {
      "id": "prod-1",
      "nombre": "Laptop XR",
      "descripcion": "Equipo ligero con 16GB de RAM",
      "precio": 1250,
      "categoria": "Computadoras",
      "score": 0.82
    }
  ]
}
```

## Estructura relevante

```
src/
‚îú‚îÄ‚îÄ agents/primary.json        # Prompt y descripci√≥n del agente √∫nico
‚îú‚îÄ‚îÄ config/index.js            # Carga de variables de entorno
‚îú‚îÄ‚îÄ orchestrator/singleAgent.js# Orquestaci√≥n del flujo agente + memoria + RAG
‚îú‚îÄ‚îÄ rag/                       # Indexador y recuperador del cat√°logo
‚îú‚îÄ‚îÄ routes/chat.js             # Endpoint REST del chat web
‚îú‚îÄ‚îÄ services/openaiService.js  # Wrapper para chat y embeddings de OpenAI
‚îî‚îÄ‚îÄ memory/index.js            # Implementaci√≥n de memoria en sesiones

web/
‚îú‚îÄ‚îÄ src/App.tsx                # UI principal del chat
‚îú‚îÄ‚îÄ src/api/client.ts          # Cliente para `/api/chat` y `/api/chat/stream`
‚îî‚îÄ‚îÄ src/components/            # Componentes de la interfaz
```

## Scripts disponibles

- `npm start`: inicia el servidor Express.
- `npm run install:web`: instala dependencias del frontend.
- `npm run build:web`: compila el frontend en modo producci√≥n.
- `npm run seed:catalog`: genera el √≠ndice de embeddings del cat√°logo.

## Widget embebible

Incluye un bot√≥n flotante que abre el chat en un iframe, configurable por atributos `data-`.

1. A√±ade el script a tu sitio:

```html
<script
  src="https://tu-dominio.com/widget.js"
  data-title="¬øHablamos?"
  data-color="#22c55e"
  data-position="bottom-right"
  data-greet="Hola üëã"
  async
></script>
```

2. Opciones:
- `data-title`: texto del bot√≥n
- `data-color`: color del bot√≥n (hex)
- `data-position`: `bottom-right` | `bottom-left`
- `data-greet`: saludo inicial (opcional)

El widget se sirve desde `GET /widget.js`.

## Licencia

ISC
